{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca665b30",
   "metadata": {},
   "source": [
    "# Log-Mel Feature Extraction for ASR\n",
    "\n",
    "This notebook implements **Log-Mel spectrogram extraction**, the primary acoustic\n",
    "representation used in modern Automatic Speech Recognition (ASR) systems.\n",
    "\n",
    "The objective is to convert raw audio waveforms into a compact, perceptually motivated\n",
    "time–frequency representation suitable for neural network training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279fb15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "from src.dataset import CommonVoiceAUSDataset\n",
    "from src.features import extract_log_mel, pad_log_mel\n",
    "from src.graph_utils import save_and_show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a63a23",
   "metadata": {},
   "source": [
    "## Loading a Sample Utterance\n",
    "\n",
    "We select a single utterance from the dataset to demonstrate\n",
    "Log-Mel feature extraction and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d25f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CommonVoiceAUSDataset(\"../data/raw/commonvoice_en_au\")\n",
    "\n",
    "sample = dataset.get_sample(0)\n",
    "audio_path = sample[\"audio_path\"]\n",
    "text = sample[\"text\"]\n",
    "\n",
    "print(\"Transcript:\")\n",
    "print(text)\n",
    "print(\"\\nAudio path:\")\n",
    "print(audio_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36489ff2",
   "metadata": {},
   "source": [
    "## Log-Mel Spectrogram Extraction\n",
    "\n",
    "The Log-Mel spectrogram captures how energy is distributed across perceptually\n",
    "motivated frequency bands over time. This representation forms the input\n",
    "to most modern ASR architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e6982",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mel = extract_log_mel(audio_path)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(\n",
    "    log_mel,\n",
    "    sr=16000,\n",
    "    hop_length=160,\n",
    "    x_axis=\"time\",\n",
    "    y_axis=\"mel\"\n",
    ")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.title(\"Log-Mel Spectrogram\")\n",
    "plt.tight_layout()\n",
    "\n",
    "save_and_show(fig, \"logmel_example.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c1bae",
   "metadata": {},
   "source": [
    "## Padding and Masking for ASR\n",
    "\n",
    "Speech utterances vary in length, but neural networks require fixed-size tensors.\n",
    "Padding standardizes feature dimensions, while masks prevent the model from\n",
    "learning from artificial silence introduced by padding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a35a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames = 1000\n",
    "\n",
    "padded_log_mel, mask = pad_log_mel(log_mel, max_frames)\n",
    "\n",
    "print(\"Original shape:\", log_mel.shape)\n",
    "print(\"Padded shape:\", padded_log_mel.shape)\n",
    "print(\"Valid frames:\", int(mask.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c971cd2c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this step, we:\n",
    "- Extracted Log-Mel spectrograms from raw audio\n",
    "- Visualized time–frequency acoustic patterns\n",
    "- Applied padding and masking for batch compatibility\n",
    "\n",
    "These features serve as the acoustic foundation for downstream ASR modeling.\n",
    "The next step introduces **text processing and tokenization**, bridging\n",
    "acoustic features with language representations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
